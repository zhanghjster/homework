---
layout: post
title: kafka stream概念和架构总结
date: 2018-12-09 22:39:24
tags:
   - kafka stream
---

### 概念

#### Kafka Stream 

kafka Stream是用户处理和分析存储在kafka中的数据的客户端库。它建立在诸如窗口、事件时间与处理时间区分、中间状态管理等重要的流处理概念之上。入门门槛底，可以很方便的嵌入到应用系统中，从小规模的验证程序到大型运算集群。kafka stream利用kafka的并行模型透明的处理一个应用程序多个示例的负载均衡。

kafka stream的特点：

1. 被设计为轻量级的类库，可以方便的嵌入到任何java程序
2. 除了kafka外没有任何其他依赖
3. 支持本地状态容错，可以实现快速高效的进行诸如窗口Join和聚合的操作
4. 支持Exactly-Once的精确处理
5. 采用一次处理一个数据的策略达到毫秒的处理延迟。支持基于事件时间窗的操作以及对延迟数据的处理
6. 提供流处理原语以及DSL

<!-- more -->


#### 流处理拓扑(Stream Processing Toplogy)

1. 流(Stream): 流代表无边界的，持续更新的数据集。它是有序的、可重放和容错的不可更改记录的序列，其中数据记录被定义为键-值对。
2. 流处理程序(Stream processing application): 它是使用kafka stream库的任何程序，通过拓扑来定义的计算逻辑，而拓扑则是通过流(edge)和流处理器(node)相连组成的图。
3. 流处理器(Stream processor): 它是处理器拓扑中的节点(node)，它代表一个处理步骤，从拓扑中的的上游处理器中一次接收一个输入记录并进行处理，随后向下游处理器产生一个或多个输出记录。

两个特殊的流处理器：

1. 源处理器(Source Processor): 它没有任何上游处理器，此报告kafka topic中消费数据并将数据转发给下游处理器。
2. 接收处理器(Sink Processor): 它没有下游处理器，从上游处理器中接收数据并发送到kafka topic。

下图为处理器拓扑的例子：

<img src="https://kafka.apache.org/21/images/streams-architecture-topology.jpg" width="400">



#### 时间(Time)

流处理的一个关键概念就是“时间”以及根据它来如何建模和集成。例如，基于时间边界定义时间窗的操作。

流中的常用时间概念包括：

1. 事件时间(Event Time): 数据记录产生的时间。
2. 处理时间(Processing Time): 数据被流处理器处理的时间。
3. 摄取时间(Ingestion Time): 数据存储到kafka分区的时间。

Kafka Stream通过TimestampExtractor接口为每个数据记录分配时间戳。每个记录的时间戳描述了流的时间进度，用于诸如窗口时间相关的操作。因此，仅当有新纪录到达处理器时，流的时间才会前进。这种由数据驱动的时间成为流时间，由此来区分实际执行的挂钟时间。TimestampExtractor的具体时间将为留时间提供不同的语义。比如，可以从数据记录的时间字段来计算，或直接返回当前的挂钟时间作为流时间。开发人员根据业务需求确定不同的时间概念。

#### 窗口化(Windowing)

窗口化可以方便控制如何将具有相同键的记录分组并进行如聚合或链接等有状态操作。窗口可以设置存留时间用于控制乱序或延迟数据处理。如果一个数据在窗口存留时间过期之后到达，它将会被丢弃。

#### 聚合(Aggregation)

聚合操作将一个输入流的多个输入记录组合成单个记录输出，比如计数或求和。

在Kafka Streams DSL中，聚合的输入流可以是KStream或KTable，但输出流将始终是KTable。这允许Kafka Streams在生成和提交值之后，根据新到达的数据更新聚合值。当有延迟到达的数据时，聚合KStream或KTable会提交新的聚合值。由于输出是KTable，因此新值在后续处理步骤中覆盖相同键的旧值。

#### 状态(States)

某些流处理程序不需要状态，这意味着每个消息的处理独立于其他消息。但，有些程序则需要维护状态，比如求和。kafka stream为这种操作提供了状态存储，流处理程序可以使用它来存储和查询数据。存储的类型可以是持久的键值存储或内存散列映射或者其他数据结构。kafka stream还提供了本地状态存储的容错和自动恢复功能。

#### 处理保证(Processing Guarantee)

在流处理中，经常被问到的是‘系统能保证每一条数据仅被处理一次吗？“，对于许多不能容忍数据丢失或重复程序而言，不能保证一次处理的流处理是不能使用的。在0.11.0.0之前，kafka 只能提供至少一次的投递保证，所以kafka stream则不能提供仅一次的处理保证。而在0.11.0.0之后，kafka允许producer通过事务向不同topic分区发送消息，进而kafka stream提供了仅一次的处理保证。更确切的说，它保证任何从kafka topic中读到的任何记录，在输出主题以及状态存储中仅反映一次状态操作。Kafka Streams与底层Kafka存储系统紧密集成，确保输入主题偏移的提交，状态存储的更新以及对输出主题的写入将以原子方式完成

#### 无序处理(Out-of-Order Handling)

除了保证每个记录将被精确处理一次之外，许多流处理应用程序将面临的另一个问题是如何处理可能影响其业务逻辑的无序数据。在Kafka Streams中，有两个原因可能导致与时间戳相关的无序数据到达

* 在主题分区内，记录的时间戳可能不会随其偏移量单调增加。由于Kafka Streams将始终尝试按照主题分区中的偏移处理记录，因此它可能导致具有较大时间戳（但较小偏移）的记录比同一主题中具有较小时间戳（但较大偏移）的记录更早处理
* 在一个正在处理多个主题分区的流任务中，如果用户将应用程序配置为不等待所有分区包含一些缓冲数据并从具有最小时间戳的分区中选择下一条处理记录，则稍后在其他主题分区获取数据时，它们的时间戳可能小于从另一个主题分区获取的处理记录。

对于无状态操作，无序数据不会影响处理逻辑，因为一次只考虑一条记录，而不查看过去处理过历史记录。但是，对于聚合和连接等有状态操作，无序数据可能导致处理逻辑不正确。如果用户想要处理这种无序数据，通常他们需要允许他们的应用程序等待更长的时间，同时在等待时间内记录他们的状态，即在延迟，成本和正确性之间做出权衡决定。特别是在Kafka Streams中，用户可以为窗口聚合配置窗口运算以实现这种权衡。

### 架构

下图显示了kafka stream程序的架构

<img src="https://kafka.apache.org/21/images/streams-architecture-overview.jpg" width="600">

#### 流分区和任务(Stream Partitions and Tasks)

kafka stream使用分区和任务作为并发模型的逻辑单元，每个流分区对应一个主题分区。Task是实例化的拓扑，每个task分配固定的分区并且不会更改。程序通过创建多个task实现扩展。

下图显示了task和分区之间的关系

<img src="https://kafka.apache.org/21/images/streams-architecture-tasks.jpg" width="600">

#### 线程模型

kafka stream允许用户配置运行多个线程，每个线程可以独立地使用处理器拓扑运行多个Task。下图显示了一个运行两个任务的线程

<img src="https://kafka.apache.org/21/images/streams-architecture-threads.jpg" width="600">

启动更多线程或更多实例仅仅是复制拓扑并使其处理Kafka分区的不同子集，从而并行处理。线程之间没有共享状态，因此不需要线程间协调。这使得跨应用程序实例和线程并行运行拓扑变得非常简单。 Kafka Streams利用Kafka的协调功能透明地处理各种流线程中Kafka主题分区的分配

#### 本地状态存储

Kafka Streams应用程序中的每个流任务可以嵌入一个或多个可通过本地状态存储，以存储和查询处理所需的数据。 Kafka Streams为这些本地存储提供容错和自动恢复功能。下图显示了两个具有专用本地状态存储的流任务。

<img src="https://kafka.apache.org/21/images/streams-architecture-states.jpg" width="600">

#### 容错

Kafka Streams的容错构建在Kafka本之上。 Kafka分区具有高可用性和复制性，因此，当流数据持久保存到Kafka时，即使应用程序失败并需要重新处理它也可用。 Kafka Streams中的任务利用Kafka消费者客户端提供的容错功能来处理故障。如果任务所在系统崩溃，Kafka Streams会自动在其余一个正在运行的应用程序实例中重新启动该任务。

此外，Kafka Streams还确保本地存储足够健壮。对于每个状态存储，它维护一个更改日志Kafka主题，在该主题中跟踪任何状态更新。这些更改日志主题也是分区的，因此每个本地状态存储实例以及访问存储的任务都有自己的专用更改日志主题分区。在更改日志主题上启用了日志压缩，以便可以安全地清除旧数据，以防止主题无限增长。如果失败的任务在另一台计算机上重新启动的计算机上运行，Kafka Streams会保证在重新启动任务处理之前，通过重播相应的更改日志主题，将其关联的状态存储恢复到故障之前的内容。因此，故障处理对最终用户完全透明。

值得注意的是状态回复的时间取决于重演更改日志主题数据的时间。为了实现快速恢复，kafka stream提供了standby机制，也就是可已配置本地状态的备份数据在多个程序上存在，这样当一个程序崩溃时，其他程序可以快速接管。

